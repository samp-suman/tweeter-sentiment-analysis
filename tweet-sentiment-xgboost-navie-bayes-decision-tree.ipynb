{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Data Link-- https://www.kaggle.com/arkhoshghalb/twitter-sentiment-analysis-hatred-speech","metadata":{"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## IMPORT LIBRARIES...","metadata":{}},{"cell_type":"code","source":"#importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport re\nimport nltk\nfrom tqdm import tqdm\nimport scipy\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom collections import Counter\n\nfrom sklearn.model_selection import RandomizedSearchCV\n\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import roc_auc_score\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#loading the data\ndf=pd.read_csv('../input/twitter-sentiment-analysis-hatred-speech/train.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.shape)   #check the shape of the data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.info())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['label'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.style.use('ggplot')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sn.set(font_scale=1.5)\nsn.set_style('whitegrid');\nax=sn.barplot(x=['Pos','Neg'], y=df.label.value_counts());\nax.set_title('DISTRIBUTION IN DATASET ACCORDING TO THE SENTIMENT',loc='center', pad=20, fontdict={'fontsize': 15,\n        'fontweight': 'bold',\n        'color': 'black',\n        'verticalalignment': 'baseline',\n        });\nax.set(xlabel='Tweets Sentiments', ylabel='No. of Tweets');\nplt.show()\nax.legend()\nax.figure.savefig('Total-positive-negative-counts.png',pad_inches=5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can observe that there are more reviews with 0 label i.e. tweet is not racist/sexist.<br>\nSo our dataset is imbalanced","metadata":{}},{"cell_type":"code","source":"y_value_counts=df['label'].value_counts()\nprint(\"Negative tweets  = \",y_value_counts[1], \"with percentage \", (y_value_counts[1]*100)/(y_value_counts[0]+y_value_counts[1]),'%')\nprint(\"Positive tweets  = \",y_value_counts[0], \"with percentage \", (y_value_counts[0]*100)/(y_value_counts[0]+y_value_counts[1]),'%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sn.set(font_scale=1.5)\nsn.set_style('whitegrid');\nax=sn.barplot(x=['Pos','Neg'], y=df.label.value_counts()*100/df.label.value_counts().sum(), palette='Greys_d');\nax.set_title('% DISTRIBUTION IN DATASET ACCORDING TO THE SENTIMENT',loc='center', pad=20, fontdict={'fontsize': 15,\n        'fontweight': 'bold',\n        'color': 'black',\n        'verticalalignment': 'baseline',\n        });\nax.set(xlabel='Tweets Sentiments', ylabel='No. of Tweets');\nplt.show()\nax.legend()\nax.figure.savefig('Total-positive-negative-counts.png',pad_inches=5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets see the classes through bar graph\ndata=dict(negative=y_value_counts[1],positive=y_value_counts[0])\ncls=data.keys()\nvalue=data.values()\n\nplt.bar(cls,value,color='maroon',width=0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***From the bar graph we can clearly see that there are more not racist tweets than the racist tweets.***","metadata":{}},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"Since the data is in text format, we have to preprocess the data and clean the data to vectorize the data.","metadata":{}},{"cell_type":"markdown","source":"First we will replace the all blank spaces, - with underscore and convert all the letters to lower case.","metadata":{}},{"cell_type":"code","source":"df['tweet']=df['tweet'].str.replace(' ','_')\ndf['tweet']=df['tweet'].str.replace('-','_')\ndf['tweet']=df['tweet'].str.lower()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.tweet[:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def expand(sent):\n    \"This function will replace english short notations with full form\"\n    \n    sent=re.sub(r\"can't\", \"can not\",sent)\n    sent=re.sub(r\"won't\", \"will not\",sent)\n    \n    sent=re.sub(r\"n\\'t\", \" not\",sent)\n    sent=re.sub(r\"\\'re\", \" are\",sent)\n    sent=re.sub(r\"\\'m\",\" am\",sent)\n    sent=re.sub(r\"\\'s\",\" is\",sent)\n    sent=re.sub(r\"\\'ll\",\" will\",sent)\n    sent=re.sub(r\"\\'ve\",\" have\",sent)\n    sent=re.sub(r\"\\'d\",\" would\",sent)\n    sent=re.sub(r\"\\'t\", \" not\",sent)\n    \n    return sent\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://gist.github.com/sebleier/554280\n# we are removing the words from the stop words list: 'no', 'nor', 'not'\nstopwords= ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n            'won', \"won't\", 'wouldn', \"wouldn't\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_tweet(text):\n    \"function for preprocess the text data\"\n    \n    preprocessed_tweet=[]\n    \n    for sentence in tqdm(text):\n        sent=expand(sentence)\n        sent=sent.replace(\"\\\\r\",\" \")\n        sent=sent.replace(\"\\\\n\",\" \")\n        sent=sent.replace('\\\\\"',\" \")\n        sent=re.sub(\"[^A-Za-z0-9]+\",\" \",sent)\n        \n        # https://gist.github.com/sebleier/554280\n        sent=\" \".join(i for i in sent.split() if i.lower() not in stopwords)\n        preprocessed_tweet.append(sent.lower().strip())\n        \n    return preprocessed_tweet\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocessed_tweets=preprocess_tweet(df['tweet'].values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['tweet']=preprocessed_tweets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"tweet\"][10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_list=[]\nfor i in df[\"tweet\"]:\n    for j in i.split(' '):\n        word_list.append(j)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"counter = Counter(word_list)\ntop10 = counter.most_common(11)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top10","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xaxes = [i[1] for i in top10]\nyaxes = [i[0] for i in top10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sn.set(font_scale=1.5)\nsn.set_style('whitegrid');\nsn.set(rc={'figure.figsize':(11.7,8.27)})\nax=sn.barplot(x=xaxes, y=yaxes);\nax.set_title('TOP WORDS IN BUILT WORDLIST',loc='center', pad=20, fontdict={'fontsize': 15,\n        'fontweight': 'bold',\n        'color': 'black',\n        'verticalalignment': 'baseline',\n        });\n# ax.set(xlabel='Tweets Sentiments', ylabel='No. of Tweets');\nplt.show()\nax.legend()\nax.figure.savefig('top10wordscount.png',pad_inches=5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df['label']==0].tweet","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"positive_word=[]\nnegative_word=[]\nfor i in df[df['label']==0].tweet:\n    for j in i.split(' '):\n        positive_word.append(j)\nfor i in df[df['label']==1].tweet:\n    for j in i.split(' '):\n        negative_word.append(j)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"positive_counter = Counter(positive_word)\nnegative_counter = Counter(negative_word)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"positive_counter.most_common(10),negative_counter.most_common(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"negative_counter.get('friday')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"w = ['good','bad','information']\ny1 = []\ny2=[]\nfor i in w:\n    y1.append(positive_counter.get(i))\n    y2.append(negative_counter.get(i))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nX_axis = np.arange(len(w))\n  \nplt.bar(X_axis-0.2 , y1, 0.4, label = 'Pos')\nplt.bar(X_axis+0.2 , y2, 0.4, label = 'Neg')\n  \nplt.xticks(X_axis, w)\nplt.xlabel(\"Words\", fontdict={'family': 'serif',\n        'color':  'darkred',\n        'weight': 'normal',\n        'size': 16,\n        })\nplt.ylabel(\"Number of Words\", fontdict={'family': 'serif',\n        'color':  'darkred',\n        'weight': 'normal',\n        'size': 16,\n        })\nplt.title(\"Most Common Words Across Sentiments\", fontdict={'family': 'serif',\n        'color':  'darkblue',\n        'weight': 'bold',\n        'size': 18,\n        })\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"positive_counter.most_common(10), negative_counter.most_common(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Now the text data is cleaned","metadata":{}},{"cell_type":"markdown","source":"### Splitting data into train and test","metadata":{}},{"cell_type":"code","source":"y=df['label']\nx=df.drop(['label'],axis=1)\n\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,stratify=y,random_state=40)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Vectorization...","metadata":{}},{"cell_type":"markdown","source":"#### TFIDF for text data","metadata":{}},{"cell_type":"code","source":"vect=TfidfVectorizer(min_df=10)\n\nvect.fit(x_train['tweet'].values)\n\ntrain_tweet=vect.transform(x_train['tweet'].values)\ntest_tweet=vect.transform(x_test['tweet'].values)\n\nprint(train_tweet.shape,y_train.shape)\nprint(test_tweet.shape,y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#calculating sentiment scores for train data\nx_train_sent=np.ndarray.tolist(x_train[\"tweet\"].values)\n\nsia=SentimentIntensityAnalyzer()\nps=[]\nfor i in range(len(x_train_sent)):\n    ps.append((sia.polarity_scores((x_train_sent[i]))))\n    \nx_train_polarity=np.array(ps)\nx_train_polarity=x_train_polarity.reshape(-1,1)\nx_train_polarity.shape\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#storing only scores of sentiment\nx_t=[]\nfor i in range(len(x_train)):\n    for j in x_train_polarity[0][0]:\n        x_t.append(x_train_polarity[i][0][j])\nx_t=np.array(x_t)\nx_t=x_t.reshape(-1,4)\nx_t.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#calculating sentiment scores for test data\nx_test_sent=np.ndarray.tolist(x_test[\"tweet\"].values)\n\nsia=SentimentIntensityAnalyzer()\nps=[]\nfor i in range(len(x_test_sent)):\n    ps.append((sia.polarity_scores((x_test_sent[i]))))\n    \nx_test_polarity=np.array(ps)\nx_test_polarity=x_test_polarity.reshape(-1,1)\nx_test_polarity.shape\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#storing only scores of sentiment\nx_tests=[]\nfor i in range(len(x_test)):\n    for j in x_test_polarity[0][0]:\n        x_tests.append(x_test_polarity[i][0][j])\nx_tests=np.array(x_tests)\nx_tests=x_tests.reshape(-1,4)\nx_tests.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Convert the vectors into scipy.sparse matrix","metadata":{}},{"cell_type":"code","source":"from scipy.sparse import hstack","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_tr=hstack((train_tweet,x_t))\nx_te=hstack((test_tweet,x_tests))\n\nprint(x_tr.shape)\nprint(x_te.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_tweet)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Now we are ready with the data.***","metadata":{}},{"cell_type":"markdown","source":"### DecisionTreeClassifier()","metadata":{}},{"cell_type":"code","source":"wt={0:1,1:5}            #since the data is imbalanced , we assign some more weight to class 1\n\nclf=DecisionTreeClassifier(class_weight=wt)\n\nparameters=dict(max_depth=[1,5,10,50],min_samples_split=[5,10,100,500])\n\nsearch=RandomizedSearchCV(clf,parameters,random_state=10)\nresult=search.fit(x_tr,y_train)\nresult.cv_results_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"search.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cls = DecisionTreeClassifier(max_depth=50,min_samples_split=5,random_state=10,class_weight=wt)\ncls.fit(x_tr,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_train=cls.predict(x_tr)\ny_pred_test=cls.predict(x_te)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_fpr,train_tpr,tr_treshold=roc_curve(y_train,y_pred_train)\ntest_fpr,test_tpr,te_treshold=roc_curve(y_test,y_pred_test)\n\ntrain_auc=auc(train_fpr,train_tpr)\ntest_auc=auc(test_fpr,test_tpr)\n\nplt.plot(train_fpr,train_tpr,label='Train AUC = '+str(train_auc))\nplt.plot(test_fpr,test_tpr,label='Test AUC = '+str(test_auc))\nplt.legend()\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title(\"AUC_Curve\")\nplt.grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***We got auc score= 0.7625***","metadata":{}},{"cell_type":"code","source":"def find_best_threshold(threshold, fpr, tpr):\n    \"\"\"it will give best threshold value that will give the least fpr\"\"\"\n    t = threshold[np.argmax(tpr*(1-fpr))]\n    \n    # (tpr*(1-fpr)) will be maximum if your fpr is very low and tpr is very high\n    print(\"the maximum value of tpr*(1-fpr)\", max(tpr*(1-fpr)), \"for threshold\", np.round(t,3))\n    \n    return t\n\ndef predict_with_best_t(proba, threshold):\n    \"\"\"this will give predictions based on best threshold value\"\"\"\n    predictions = []\n    for i in proba:\n        if i>=threshold:\n            predictions.append(1)\n        else:\n            predictions.append(0)\n    return predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#computing confusion matrix for set_1\n\nfrom sklearn.metrics import confusion_matrix\nbest_t = find_best_threshold(tr_treshold, train_fpr, train_tpr)\nprint(\"Train confusion matrix\")\nm_tr=(confusion_matrix(y_train, predict_with_best_t(y_pred_train, best_t)))\nprint(m_tr)\nprint(\"Test confusion matrix\")\nm_te=(confusion_matrix(y_test, predict_with_best_t(y_pred_test, best_t)))\nprint(m_te)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_pred_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3 = pd.DataFrame(classification_report(y_pred_test, \n                                        y_test, digits=2,\n                                        output_dict=True)).T\n\ndf3['support'] = df1.support.apply(int)\n\ndf3.style.background_gradient(cmap='viridis',\n                             subset=pd.IndexSlice['0':'9', :'f1-score'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dt_df = pd.DataFrame(columns=['tweet', 'sentiment-predicted', 'label'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def color_negative_red(value):\n    \"\"\"\n    Colors elements in a dateframe\n    green if positive and red if\n    negative. Does not color NaN\n    values.\n    \"\"\"\n\n    if value == 'Pos':\n        color = 'green'\n    else:\n        color='red'\n\n    return 'color: %s' % color","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dt_df = pd.DataFrame(columns=['tweet', 'sentiment-predicted', 'label'])\ndt_df['tweet'] = x_test['tweet']\ndt_df['sentiment-predicted'] = y_pred_test\ndt_df['label'] =y_test\ndt_df.replace(to_replace=[0,1],value=['Pos','Neg'], inplace=True)\n(dt_df.sample(10)[['tweet','sentiment-predicted','label']].style\n    .applymap(color_negative_red, subset=['sentiment-predicted','label']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## NAIVE BAYES","metadata":{}},{"cell_type":"markdown","source":"### CountVectorizer()","metadata":{}},{"cell_type":"code","source":"vec=CountVectorizer(min_df=10)\nvec.fit(x_train['tweet'].values)\n\nx_tr_count=vec.transform(x_train['tweet'].values)\nx_te_count=vec.transform(x_test['tweet'].values)\nx_tr_count.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_tr_data=hstack((x_tr_count,x_t))\nx_te_data=hstack((x_te_count,x_tests))\n\nx_trn=scipy.sparse.csr_matrix(x_tr_count)\nx_tst=scipy.sparse.csr_matrix(x_te_count)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mod = MultinomialNB()\nmod.fit(x_trn,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_pred=mod.predict(x_trn)\ntest_pred=mod.predict(x_tst)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_fpr,train_tpr,tr_treshold=roc_curve(y_train,train_pred)\ntest_fpr,test_tpr,te_treshold=roc_curve(y_test,test_pred)\n\ntrain_auc=auc(train_fpr,train_tpr)\ntest_auc=auc(test_fpr,test_tpr)\n\nplt.plot(train_fpr,train_tpr,label='Train AUC = '+str(train_auc))\nplt.plot(test_fpr,test_tpr,label='Test AUC = '+str(test_auc))\nplt.legend()\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title(\"AUC_Curve\")\nplt.grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***TEST AUC = 0.8157***","metadata":{}},{"cell_type":"code","source":"#get the summary of this model\n\nprint(classification_report(test_pred, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = pd.DataFrame(classification_report(mod.predict(x_tst), \n                                        y_test, digits=2,\n                                        output_dict=True)).T\n\ndf1['support'] = df1.support.apply(int)\n\ndf1.style.background_gradient(cmap='viridis',\n                             subset=pd.IndexSlice['0':'9', :'f1-score'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dt_df = pd.DataFrame(columns=['tweet', 'sentiment-predicted', 'label'])\ndt_df['tweet'] = x_test['tweet']\ndt_df['sentiment-predicted'] = test_pred\ndt_df['label'] =y_test\ndt_df.replace(to_replace=[0,1],value=['Pos','Neg'], inplace=True)\n(dt_df.sample(10)[['tweet','sentiment-predicted','label']].style\n    .applymap(color_negative_red, subset=['sentiment-predicted','label']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## XGBOOST","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"xg=XGBClassifier(use_label_encoder=False)\nparam=dict(max_depth=[4,6,8,10],n_estimators=[100,500,1000,1500])\nsearch=RandomizedSearchCV(xg,param,random_state=10,)\nsrch=search.fit(x_tr,y_train,)\nsrch.cv_results_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"srch.best_estimator_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n              min_child_weight=1, missing=None, monotone_constraints='()',\n              n_estimators=500, n_jobs=8, num_parallel_tree=1, random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n              tree_method='exact', validate_parameters=1, verbosity=None,).fit(x_tr, y_train)\n\nprediction = xgb.predict(x_te) \n\nf1_score(y_test, prediction)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_prediction=xgb.predict(x_tr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_fpr,train_tpr,tr_treshold=roc_curve(y_train,train_prediction)\ntest_fpr,test_tpr,te_treshold=roc_curve(y_test,prediction)\n\ntrain_auc=auc(train_fpr,train_tpr)\ntest_auc=auc(test_fpr,test_tpr)\n\nplt.plot(train_fpr,train_tpr,label='Train AUC = '+str(train_auc))\nplt.plot(test_fpr,test_tpr,label='Test AUC = '+str(test_auc))\nplt.legend()\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title(\"AUC_Curve\")\nplt.grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***TEST AUC = 0.7280***","metadata":{}},{"cell_type":"code","source":"print(classification_report(y_test, prediction))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2 = pd.DataFrame(classification_report(y_test, prediction, digits=2,\n                                        output_dict=True)).T\n\ndf2['support'] = df2.support.apply(int)\n\ndf2.style.background_gradient(cmap='viridis',\n                             subset=pd.IndexSlice['0':'1', :'f1-score'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dt_df = pd.DataFrame(columns=['tweet', 'sentiment-predicted', 'label'])\ndt_df['tweet'] = x_test['tweet']\ndt_df['sentiment-predicted'] = prediction\ndt_df['label'] =y_test\ndt_df.replace(to_replace=[0,1],value=['Pos','Neg'], inplace=True)\n(dt_df.sample(10)[['tweet','sentiment-predicted','label']].style\n    .applymap(color_negative_red, subset=['sentiment-predicted','label']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SUMMARY","metadata":{}},{"cell_type":"markdown","source":"### DECISION TREE","metadata":{}},{"cell_type":"markdown","source":"                   precision    recall  f1-score   support\n\n              0       0.97      0.95      0.96      5945\n              1       0.48      0.57      0.52       448\n\n    accuracy                               0.93      6393\n    macro avg          0.72      0.76      0.74      6393\n    weighted avg       0.93      0.93      0.93      6393\n","metadata":{}},{"cell_type":"markdown","source":"### NAIVE BAYES","metadata":{}},{"cell_type":"markdown","source":"                   precision    recall  f1-score   support\n\n              0       0.97      0.97      0.97      5945\n              1       0.63      0.66      0.64       448\n\n    accuracy                               0.95      6393\n    macro avg          0.80      0.82      0.81      6393\n    weighted avg       0.95      0.95      0.95      6393\n","metadata":{}},{"cell_type":"markdown","source":"### XGBOOST","metadata":{}},{"cell_type":"markdown","source":"                     precision    recall  f1-score   support\n\n               0       0.96      0.99      0.98      5945\n               1       0.77      0.47      0.58       448\n\n    accuracy                               0.95      6393\n    macro avg          0.87      0.73      0.78      6393\n    weighted avg       0.95      0.95      0.95      6393\n\nâ€‹","metadata":{}},{"cell_type":"markdown","source":"|MODEL|TEST AUC|\n|----|----|\n|DECISION TREE|0.7625|\n|NAIVE BAYES|0.8157|\n|XGBOOST|0.7280|","metadata":{}},{"cell_type":"code","source":"training_size = 25569\nXGB  = ['XGBOOST',25569,'NA',0.7280, 0.95]\nnb  = ['NAIVE BAYES',25569,'NA',0.8157, 0.95]\nXGB  = ['DECISION TREE',25569,'NA',0.7625, 0.93]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}